{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T12:53:00.650163Z",
     "start_time": "2019-11-04T12:53:00.385089Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T12:53:02.895339Z",
     "start_time": "2019-11-04T12:53:00.945823Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai_timeseries import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROCKET is a new time series classification method that achieves state-of-the-art performance with much faster speed than existing methods. It works by randomly generating a large number (default 20k) of features. Those features can then be used with any classifier.\n",
    "\n",
    "[ROCKET paper by Dempster, Petitjean, and Webb](https://arxiv.org/pdf/1910.13051.pdf)\n",
    "\n",
    "[Python implementation by Ignacio Oguiza](https://github.com/timeseriesAI/timeseriesAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A natural question to ask is, of those 20k features, is the model using all of them somewhat equally, or is it relying on a relatively small number of \"good\" features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic implementation of ROCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, I used a dataset from the UCR archive with only two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T12:55:25.082078Z",
     "start_time": "2019-11-04T12:55:24.973735Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250, 720), (250, 720))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data\n",
    "X_train, y_train, X_valid, y_valid = get_UCR_data('Computers')\n",
    "seq_len = X_train.shape[-1]\n",
    "X_train = X_train[:, 0].astype(np.float64)\n",
    "X_valid = X_valid[:, 0].astype(np.float64)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T12:55:26.731150Z",
     "start_time": "2019-11-04T12:55:26.698291Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize\n",
    "X_train = (X_train - X_train.mean(axis = 1, keepdims = True)) / (X_train.std(axis = 1, keepdims = True) + 1e-8)\n",
    "X_valid = (X_valid - X_valid.mean(axis = 1, keepdims = True)) / (X_valid.std(axis = 1, keepdims = True) + 1e-8)\n",
    "X_train.mean(axis = 1, keepdims = True).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my model of choice, I used logistic regression because it's easy to see how much the model is using each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T12:55:41.948132Z",
     "start_time": "2019-11-04T12:55:40.500910Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.624"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the model\n",
    "kernels = generate_kernels(seq_len, 10000)\n",
    "X_train_tfm = apply_kernels(X_train, kernels)\n",
    "X_valid_tfm = apply_kernels(X_valid, kernels)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = sklearn.linear_model.LogisticRegression()\n",
    "model.fit(X_train_tfm, y_train)\n",
    "model.score(X_valid_tfm, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the learned weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = (model.coef_).flatten()\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.05, 0.05)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.hist(w, bins=100)\n",
    "plt.xlim([-.05,.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like most values are very close to 0, with just a few larger values. This suggests the model is relying mostly on just a few features. Let's filter for features with a magnitude greater than 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3284"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ixs = np.abs(w) > 0.01\n",
    "ixs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250, 3284), (250, 3284))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small = X_train_tfm[:, ixs]\n",
    "X_valid_small = X_valid_tfm[:, ixs]\n",
    "X_train_small.shape, X_valid_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.628"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sklearn.linear_model.LogisticRegression()\n",
    "model.fit(X_train_small, y_train)\n",
    "model.score(X_valid_small, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! It appears it's able to get nearly the same accuracy with less than 20% of the features.\n",
    "\n",
    "What if we went even farther and tried to select just a handful of the best features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6363,  6589,  3915, 14209,  7049, 14367, 18367,  9359, 17121, 17451])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ixs = np.argpartition(np.abs(w), -10)[-10:] # select the 10 biggest features\n",
    "ixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.051365, -0.05146 , -0.052487,  0.052149,  0.05235 , -0.053535, -0.055356,  0.066172,  0.062442,  0.054786])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[ixs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250, 10), (250, 10))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small = X_train_tfm[:, ixs]\n",
    "X_valid_small = X_valid_tfm[:, ixs]\n",
    "X_train_small.shape, X_valid_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.588"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sklearn.linear_model.LogisticRegression()\n",
    "model.fit(X_train_small, y_train)\n",
    "model.score(X_valid_small, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my experiments the results of going down to just 10 features were highly variable: sometimes it continued to perform well, other times the accuracy continued to make a big hit. Perhaps that's overkill. Let's automate the process of trying different numbers of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.652"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000 # number of features to keep\n",
    "\n",
    "ixs = np.argpartition(np.abs(w), -n)[-n:] # get the features with the biggest weights\n",
    "\n",
    "X_train_small = X_train_tfm[:, ixs]\n",
    "X_valid_small = X_valid_tfm[:, ixs]\n",
    "\n",
    "model = sklearn.linear_model.LogisticRegression()\n",
    "model.fit(X_train_small, y_train)\n",
    "model.score(X_valid_small, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While results are somewhat variable depending on the dataset and trial, I found you can usually get comparable or sometimes even better results with a small fraction of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the point?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While ROCKET is much faster than other methods with comparable accuracy, it can bog down with very large datasets. Feature selection is a promising way to speed up performance even more. Of course, you'll still have to train a model on all the features initially, but once you've isolated the key features, inference is really easy.\n",
    "\n",
    "Qualitatively, this gives us a way to dig into what ROCKET is actually doing. An interesting next step would be to examine the kernels that produce the features with the highest weights. Can we identify kernels that pick up on classic time series features like trend and seasonality, similar to how a 2d convolution can be an \"edge detector\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
